# Settings to configure
# * Akka Cluster, serialization using Jackson, and use only loopback address for Artery communication

akka {
  loglevel = DEBUG

  actor {
    provider = cluster

    # TODO: Change this to JSON or some other more reasonable serialization
    allow-java-serialization = on
  }

  # For the sample, just bind to loopback and do not allow access from the network
  # the port is overridden by the logic in main class
  remote.artery {
    canonical.port = 2551
    canonical.hostname = 127.0.0.1
  }

  cluster {
    seed-nodes = [
      "akka://FileIngestion@127.0.0.1:2551"
    ]
  }

  # use JDBC to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "jdbc-journal"
    auto-start-journals = ["jdbc-journal"]
    snapshot-store.plugin = "jdbc-snapshot-store"
    auto-start-snapshot-stores = ["jdbc-journal"]
  }

}

# Configuration for akka-persistence-cassandra
jdbc-journal {
  slick = ${slick}
}

jdbc-snapshot-store {
  slick = ${slick}
}

jdbc-read-journal {
  slick = ${slick}
}

slick {
  profile = "slick.jdbc.H2Profile$"
  db {
    url = "jdbc:h2:~/test"
    user = "root"
    password = "root"
    driver = "org.h2.Driver"
    numThreads = 5
    maxConnections = 5
    minConnections = 1
  }
}

event-processor {
  id = "EventProcessor"            // type name of sharded event processor
  keep-alive-interval = 2 seconds  // event-processors ping interval
  tag-prefix = "file-ingest-slice"       // even processor tag prefix
  parallelism = 4                  // number of event processors
}

file-ingest.http.port = 0
file-ingest.askTimeout = 5 s


